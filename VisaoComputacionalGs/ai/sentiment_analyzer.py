"""
EqualMind - An√°lise de Sentimento com Deep Learning
Utiliza modelos transformer para portugu√™s (BERT) + OpenAI GPT
"""
import logging
from textblob import TextBlob
import nltk
import torch
import torch.nn.functional as F
from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, pipeline
from config import Config
from ai.gpt_service import gpt_service

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Download de recursos necess√°rios
try:
    nltk.download('punkt', quiet=True)
    nltk.download('stopwords', quiet=True)
except:
    pass


class SentimentAnalyzer:
    """
    Analisador de Sentimento usando Deep Learning
    Utiliza modelo BERT pr√©-treinado para portugu√™s (neuralmind/bert-base-portuguese-cased)
    Processa texto em portugu√™s e retorna sentimento + score
    """
    
    def __init__(self):
        self.modelo_carregado = False
        self.modelo_bert = None
        self.tokenizer = None
        self.sentiment_pipeline = None
        self.use_embeddings = False  # Flag para usar embeddings se modelo n√£o for fine-tuned
        self.model_name = Config.MODELO_SENTIMENTO
        self._carregar_modelo()
    
    def _carregar_modelo(self):
        """
        Carrega o modelo de Deep Learning (BERT) para an√°lise de sentimento
        Usa modelo pr√©-treinado neuralmind/bert-base-portuguese-cased
        """
        try:
            logger.info(f"üîÑ Carregando modelo de Deep Learning: {self.model_name}")
            
            # Tentar carregar modelo fine-tuned para sentimento primeiro
            # Se n√£o encontrar, usar modelo base com embeddings
            try:
                # Tentar pipeline de sentiment-analysis (requer modelo fine-tuned)
                self.sentiment_pipeline = pipeline(
                    "sentiment-analysis",
                    model=self.model_name,
                    tokenizer=self.model_name,
                    device=0 if torch.cuda.is_available() else -1,
                    return_all_scores=True
                )
                self.modelo_carregado = True
                logger.info("‚úÖ Modelo BERT carregado com sucesso (pipeline sentiment-analysis)")
                
            except Exception as e:
                logger.info(f"‚ÑπÔ∏è Pipeline de sentiment n√£o dispon√≠vel, tentando modelo base: {e}")
                
                # Tentar carregar modelo fine-tuned para classifica√ß√£o
                try:
                    self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
                    self.model_bert = AutoModelForSequenceClassification.from_pretrained(
                        self.model_name,
                        device_map="auto" if torch.cuda.is_available() else None
                    )
                    self.model_bert.eval()
                    self.modelo_carregado = True
                    logger.info("‚úÖ Modelo BERT carregado (SequenceClassification)")
                    
                except Exception as e2:
                    logger.info(f"‚ÑπÔ∏è Modelo de classifica√ß√£o n√£o dispon√≠vel, usando embeddings: {e2}")
                    
                    # Fallback: usar modelo base BERT com embeddings
                    try:
                        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
                        self.model_bert = AutoModel.from_pretrained(
                            self.model_name,
                            device_map="auto" if torch.cuda.is_available() else None
                        )
                        self.model_bert.eval()
                        self.use_embeddings = True
                        self.modelo_carregado = True
                        logger.info("‚úÖ Modelo BERT base carregado (usando embeddings para an√°lise)")
                        
                    except Exception as e3:
                        logger.error(f"‚ùå Erro ao carregar modelo BERT: {e3}")
                        logger.warning("‚ö†Ô∏è Usando an√°lise b√°sica como fallback")
                        self.modelo_carregado = False
                    
        except Exception as e:
            logger.error(f"‚ùå Erro geral ao carregar modelo: {e}")
            logger.warning("‚ö†Ô∏è Usando an√°lise b√°sica como fallback")
            self.modelo_carregado = False
    
    def _analisar_com_bert(self, texto):
        """
        An√°lise de sentimento usando modelo BERT de Deep Learning
        Retorna score de sentimento baseado no modelo pr√©-treinado
        """
        if not self.modelo_carregado or not texto:
            return None
        
        try:
            # Limitar tamanho do texto (BERT tem limite de tokens)
            max_length = 512
            if len(texto) > max_length:
                texto = texto[:max_length]
            
            # Usar pipeline se dispon√≠vel (mais simples)
            if self.sentiment_pipeline:
                try:
                    resultados = self.sentiment_pipeline(texto)
                    
                    # Processar resultados do pipeline
                    # O pipeline retorna lista de scores para cada label
                    if resultados and len(resultados) > 0:
                        # Normalmente retorna [{'label': 'POSITIVE', 'score': 0.9}, {'label': 'NEGATIVE', 'score': 0.1}]
                        # ou [{'label': 'LABEL_0', 'score': 0.1}, {'label': 'LABEL_1', 'score': 0.9}]
                        scores = resultados[0] if isinstance(resultados[0], list) else resultados
                        
                        # Encontrar scores positivo e negativo
                        score_positivo = 0.0
                        score_negativo = 0.0
                        
                        for item in scores:
                            label = str(item.get('label', '')).upper()
                            score = item.get('score', 0.0)
                            
                            # Verificar diferentes formatos de labels
                            if 'POS' in label or 'POSITIVE' in label or 'LABEL_1' in label or label == '1':
                                score_positivo = score
                            elif 'NEG' in label or 'NEGATIVE' in label or 'LABEL_0' in label or label == '0':
                                score_negativo = score
                        
                        # Se n√£o encontrou labels espec√≠ficos, usar o score mais alto como positivo
                        if score_positivo == 0.0 and score_negativo == 0.0 and len(scores) >= 2:
                            # Assumir que o maior score √© positivo
                            scores_sorted = sorted(scores, key=lambda x: x.get('score', 0), reverse=True)
                            score_positivo = scores_sorted[0].get('score', 0.5)
                            score_negativo = scores_sorted[1].get('score', 0.5) if len(scores_sorted) > 1 else 1.0 - score_positivo
                        
                        # Calcular polaridade (-1 a 1)
                        if score_positivo > 0 or score_negativo > 0:
                            polaridade = score_positivo - score_negativo
                            logger.info(f"‚úÖ Pipeline BERT: positivo={score_positivo:.3f}, negativo={score_negativo:.3f}, polaridade={polaridade:.3f}")
                            return polaridade
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro no pipeline BERT: {e}, tentando m√©todo direto...")
                    # Continuar para m√©todo direto
                    
            # Fallback: usar modelo e tokenizer diretamente
            elif self.tokenizer and self.model_bert:
                # Tokenizar texto
                inputs = self.tokenizer(
                    texto,
                    return_tensors="pt",
                    truncation=True,
                    max_length=512,
                    padding=True
                )
                
                # Mover para GPU se dispon√≠vel
                device = "cuda" if torch.cuda.is_available() else "cpu"
                if torch.cuda.is_available():
                    inputs = {k: v.to(device) for k, v in inputs.items()}
                    if hasattr(self.model_bert, 'to'):
                        self.model_bert = self.model_bert.to(device)
                
                # Fazer infer√™ncia
                with torch.no_grad():
                    outputs = self.model_bert(**inputs)
                    
                    # Se usar embeddings (modelo base), fazer an√°lise baseada em embeddings
                    if self.use_embeddings:
                        # Obter embeddings do [CLS] token
                        if hasattr(outputs, 'last_hidden_state'):
                            embeddings = outputs.last_hidden_state
                        elif hasattr(outputs, 'pooler_output'):
                            embeddings = outputs.pooler_output
                        else:
                            # Tentar obter do primeiro token
                            embeddings = outputs[0][:, 0, :]  # [CLS] token
                        
                        # An√°lise de sentimento baseada em embeddings
                        # Usar palavras-chave positivas/negativas como refer√™ncia
                        palavras_pos_ref = ['bom', '√≥timo', 'feliz', 'satisfeito', 'alegre']
                        palavras_neg_ref = ['ruim', 'triste', 'estressado', 'cansado', 'ansioso']
                        
                        # Tokenizar palavras de refer√™ncia e obter seus embeddings
                        pos_embeddings = []
                        neg_embeddings = []
                        
                        for palavra in palavras_pos_ref:
                            try:
                                tokens = self.tokenizer(palavra, return_tensors="pt", padding=True, truncation=True)
                                if torch.cuda.is_available():
                                    tokens = {k: v.to(device) for k, v in tokens.items()}
                                with torch.no_grad():
                                    out = self.model_bert(**tokens)
                                    if hasattr(out, 'last_hidden_state'):
                                        pos_embeddings.append(out.last_hidden_state[:, 0, :].mean(dim=0))
                            except:
                                pass
                        
                        for palavra in palavras_neg_ref:
                            try:
                                tokens = self.tokenizer(palavra, return_tensors="pt", padding=True, truncation=True)
                                if torch.cuda.is_available():
                                    tokens = {k: v.to(device) for k, v in tokens.items()}
                                with torch.no_grad():
                                    out = self.model_bert(**tokens)
                                    if hasattr(out, 'last_hidden_state'):
                                        neg_embeddings.append(out.last_hidden_state[:, 0, :].mean(dim=0))
                            except:
                                pass
                        
                        # Calcular similaridade com embeddings de refer√™ncia
                        if pos_embeddings and neg_embeddings:
                            # M√©dia dos embeddings de refer√™ncia
                            pos_ref = torch.stack(pos_embeddings).mean(dim=0)
                            neg_ref = torch.stack(neg_embeddings).mean(dim=0)
                            
                            # Embedding do texto (usar [CLS] token)
                            text_embedding = embeddings[:, 0, :].squeeze() if len(embeddings.shape) > 2 else embeddings.squeeze()
                            
                            # Calcular similaridade cosseno
                            cos_sim_pos = F.cosine_similarity(text_embedding.unsqueeze(0), pos_ref.unsqueeze(0))
                            cos_sim_neg = F.cosine_similarity(text_embedding.unsqueeze(0), neg_ref.unsqueeze(0))
                            
                            # Normalizar para -1 a 1
                            polaridade = (cos_sim_pos.item() - cos_sim_neg.item()) / 2.0
                            return max(-1.0, min(1.0, polaridade))
                        else:
                            # Se n√£o conseguiu embeddings de refer√™ncia, usar an√°lise b√°sica
                            return None
                    
                    # Se √© modelo de classifica√ß√£o (SequenceClassification)
                    elif hasattr(outputs, 'logits'):
                        logits = outputs.logits
                        probs = F.softmax(logits, dim=-1)
                        
                        if probs.shape[1] >= 2:
                            score_negativo = probs[0][0].item()
                            score_positivo = probs[0][1].item()
                            polaridade = score_positivo - score_negativo
                            return polaridade
                        else:
                            return (probs[0][0].item() - 0.5) * 2
                    else:
                        return None
                        
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro na an√°lise BERT: {e}")
            return None
        
        return None
    
    def _analisar_portugues_basico(self, texto):
        """An√°lise b√°sica de sentimento em portugu√™s usando palavras-chave (fallback)"""
        texto_lower = texto.lower()
        
        # Palavras positivas
        palavras_positivas = [
            'bem', 'bom', '√≥timo', 'excelente', 'feliz', 'satisfeito', 'satisfeita',
            'alegre', 'contente', 'animado', 'animada', 'motivado', 'motivada',
            '√≥tima', 'bom dia', 'tudo bem', 'est√° bem', 'estou bem', 'estamos bem',
            'perfeito', 'maravilhoso', 'gratid√£o', 'grato', 'grata', 'satisfa√ß√£o',
            'prazer', 'entusiasmado', 'entusiasmada', 'confiante', 'tranquilo', 'tranquila'
        ]
        
        # Palavras negativas
        palavras_negativas = [
            'mal', 'ruim', 'p√©ssimo', 'terr√≠vel', 'triste', 'infeliz', 'insatisfeito',
            'insatisfeita', 'deprimido', 'deprimida', 'ansioso', 'ansiosa', 'estressado',
            'estressada', 'cansado', 'cansada', 'desmotivado', 'desmotivada', 'preocupado',
            'preocupada', 'angustiado', 'angustiada', 'frustrado', 'frustrada', 'irritado',
            'irritada', 'nervoso', 'nervosa', 'medo', 'medo', 'p√¢nico', 'desesperado'
        ]
        
        # Contar ocorr√™ncias
        count_positivo = sum(1 for palavra in palavras_positivas if palavra in texto_lower)
        count_negativo = sum(1 for palavra in palavras_negativas if palavra in texto_lower)
        
        # Calcular score
        total_palavras = len(texto.split())
        if total_palavras == 0:
            return 0.0
        
        # Score baseado na diferen√ßa entre positivo e negativo
        score = (count_positivo - count_negativo) / max(total_palavras, 1) * 2
        score = max(-1.0, min(1.0, score))  # Limitar entre -1 e 1
        
        return score
    
    def analisar_texto(self, texto, usar_gpt=True):
        """
        An√°lise de sentimento h√≠brida usando Deep Learning (BERT) + GPT (se dispon√≠vel)
        
        Pipeline de an√°lise:
        1. Tenta usar modelo BERT (Deep Learning) - PRIORIDADE
        2. Se BERT falhar, usa an√°lise b√°sica por palavras-chave
        3. Opcionalmente combina com GPT para an√°lise avan√ßada
        
        Args:
            texto (str): Texto a ser analisado
            usar_gpt (bool): Se deve usar GPT para an√°lise avan√ßada
            
        Returns:
            dict: An√°lise completa com sentimento, score e insights
        """
        if not texto or len(texto.strip()) < 3:
            return {
                'sentimento': 'neutro',
                'score': 0.0,
                'confianca': 0.0,
                'metodo': 'vazio'
            }
        
        try:
            polaridade = None
            metodo_usado = 'basico'
            confianca_base = 0.5
            
            # üß† PRIORIDADE 1: An√°lise com Deep Learning (BERT)
            if self.modelo_carregado:
                logger.info("üß† Usando modelo BERT (Deep Learning) para an√°lise...")
                polaridade_bert = self._analisar_com_bert(texto)
                
                if polaridade_bert is not None:
                    polaridade = polaridade_bert
                    metodo_usado = 'deep_learning_bert'
                    confianca_base = 0.85  # Alta confian√ßa no modelo BERT
                    logger.info(f"‚úÖ An√°lise BERT conclu√≠da: polaridade={polaridade:.3f}")
            
            # üîÑ FALLBACK: Se BERT n√£o funcionou, usar an√°lise b√°sica
            if polaridade is None:
                logger.info("‚ö†Ô∏è BERT n√£o dispon√≠vel, usando an√°lise b√°sica...")
                score_portugues = self._analisar_portugues_basico(texto)
                
                # Tentar TextBlob como complemento
                try:
                    analise = TextBlob(texto)
                    polaridade_textblob = analise.sentiment.polarity
                    # Combinar an√°lises (dar mais peso √† an√°lise em portugu√™s)
                    polaridade = (score_portugues * 0.7) + (polaridade_textblob * 0.3)
                except:
                    polaridade = score_portugues
                
                metodo_usado = 'basico_fallback'
                confianca_base = 0.6
            
            # Classificar sentimento baseado na polaridade
            if polaridade > 0.15:
                sentimento = 'positivo'
            elif polaridade < -0.15:
                sentimento = 'negativo'
            else:
                sentimento = 'neutro'
            
            # Calcular confian√ßa final
            confianca = min(abs(polaridade) * 1.2 + confianca_base * 0.3, 1.0)
            
            resultado = {
                'sentimento': sentimento,
                'score': round(polaridade, 3),
                'confianca': round(confianca, 2),
                'metodo': metodo_usado,
                'deep_learning': self.modelo_carregado,  # Indica se usou DL
                'detalhes': {
                    'polaridade': polaridade,
                    'palavras': len(texto.split()),
                    'modelo': self.model_name if self.modelo_carregado else None
                }
            }
            
            # üöÄ PRIORIDADE 2: An√°lise avan√ßada com GPT (se dispon√≠vel e solicitado)
            if usar_gpt and gpt_service.verificar_disponibilidade():
                logger.info("ü§ñ Combinando com GPT para an√°lise avan√ßada...")
                analise_gpt = gpt_service.analisar_sentimento_avancado(texto)
                
                if analise_gpt:
                    resultado['gpt_analise'] = analise_gpt
                    resultado['metodo'] = f'{metodo_usado}_+_gpt'
                    
                    # Usar sentimento do GPT se dispon√≠vel (mais confi√°vel para contexto)
                    sentimento_gpt = analise_gpt.get('sentimento_primario', '').lower()
                    if sentimento_gpt in ['positivo', 'negativo', 'neutro']:
                        # Combinar sentimento BERT com GPT (peso maior para GPT em contexto)
                        if metodo_usado == 'deep_learning_bert':
                            # Se ambos concordam, aumentar confian√ßa
                            if sentimento_gpt == sentimento:
                                resultado['confianca'] = min(resultado['confianca'] + 0.1, 1.0)
                            else:
                                # Se discordam, dar mais peso ao GPT (contexto)
                                resultado['sentimento'] = sentimento_gpt
                        else:
                            # Se n√£o usou BERT, confiar mais no GPT
                            resultado['sentimento'] = sentimento_gpt
                            if sentimento_gpt == 'positivo':
                                resultado['score'] = max(resultado['score'], 0.3)
                            elif sentimento_gpt == 'negativo':
                                resultado['score'] = min(resultado['score'], -0.3)
                            resultado['confianca'] = min(resultado['confianca'] + 0.2, 1.0)
            
            logger.info(f"üìä Sentimento analisado: {sentimento} (score: {resultado['score']}, m√©todo: {resultado['metodo']}, DL: {self.modelo_carregado})")
            return resultado
            
        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise de sentimento: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return {
                'sentimento': 'erro',
                'score': 0.0,
                'confianca': 0.0,
                'metodo': 'erro'
            }
    
    def analisar_emocoes_numerico(self, estresse, felicidade, ansiedade, motivacao, comentario_sentimento=None):
        """
        Analisa os valores num√©ricos e gera insights
        Considera tamb√©m o sentimento do coment√°rio se dispon√≠vel
        
        Args:
            estresse (int): 1-10
            felicidade (int): 1-10
            ansiedade (int): 1-10
            motivacao (int): 1-10
            comentario_sentimento (dict): Resultado da an√°lise de sentimento do coment√°rio (opcional)
            
        Returns:
            dict: An√°lise e classifica√ß√£o do estado emocional
        """
        # C√°lculo do √≠ndice de bem-estar (0-100)
        # Cada m√©trica contribui com at√© 25 pontos (10 * 2.5)
        # Estresse e ansiedade: quanto menor, melhor (10 - valor)
        # Felicidade e motiva√ß√£o: quanto maior, melhor (valor direto)
        indice_bem_estar = (
            (10 - estresse) * 2.5 +
            felicidade * 2.5 +
            (10 - ansiedade) * 2.5 +
            motivacao * 2.5
        )
        # N√£o dividir por 4! Cada componente j√° est√° na escala correta (0-25)
        
        # Ajustar √≠ndice baseado no sentimento do coment√°rio
        if comentario_sentimento:
            sentimento = comentario_sentimento.get('sentimento', 'neutro')
            score_sentimento = comentario_sentimento.get('score', 0.0)
            
            # Se o coment√°rio for positivo, aumentar o √≠ndice
            if sentimento == 'positivo' and score_sentimento > 0.2:
                # Aumentar √≠ndice em at√© 15 pontos se coment√°rio muito positivo
                bonus = min(score_sentimento * 20, 15)
                indice_bem_estar = min(indice_bem_estar + bonus, 100)
                logger.info(f"üìà Ajuste positivo baseado no coment√°rio: +{bonus:.1f} pontos")
            # Se o coment√°rio for negativo, diminuir o √≠ndice
            elif sentimento == 'negativo' and score_sentimento < -0.2:
                # Diminuir √≠ndice em at√© 15 pontos se coment√°rio muito negativo
                penalidade = min(abs(score_sentimento) * 20, 15)
                indice_bem_estar = max(indice_bem_estar - penalidade, 0)
                logger.info(f"üìâ Ajuste negativo baseado no coment√°rio: -{penalidade:.1f} pontos")
        
        # Classifica√ß√£o ajustada para escala 0-100
        if indice_bem_estar >= 80:
            classificacao = 'excelente'
            cor = 'green'
        elif indice_bem_estar >= 65:
            classificacao = 'bom'
            cor = 'lightgreen'
        elif indice_bem_estar >= 50:
            classificacao = 'moderado'
            cor = 'yellow'
        elif indice_bem_estar >= 35:
            classificacao = 'preocupante'
            cor = 'orange'
        else:
            classificacao = 'cr√≠tico'
            cor = 'red'
        
        # Identificar principais problemas (thresholds mais realistas)
        problemas = []
        if estresse >= 8:
            problemas.append('Estresse muito elevado')
        elif estresse >= 6:
            problemas.append('Estresse moderado')
            
        if felicidade <= 2:
            problemas.append('Felicidade muito baixa')
        elif felicidade <= 4:
            problemas.append('Felicidade baixa')
            
        if ansiedade >= 8:
            problemas.append('Ansiedade muito alta')
        elif ansiedade >= 6:
            problemas.append('Ansiedade moderada')
            
        if motivacao <= 2:
            problemas.append('Motiva√ß√£o muito baixa')
        elif motivacao <= 4:
            problemas.append('Motiva√ß√£o baixa')
        
        # Se o √≠ndice √© alto (bom estado), n√£o mostrar problemas menores
        if indice_bem_estar >= 70:
            problemas = []  # N√£o mostrar problemas se o estado √© excelente
        elif indice_bem_estar >= 55:
            # Se est√° bom, s√≥ mostrar problemas graves
            problemas = [p for p in problemas if 'muito' in p.lower()]
        # Se n√£o h√° problemas significativos e o coment√°rio √© positivo, n√£o mostrar problemas
        elif comentario_sentimento and comentario_sentimento.get('sentimento') == 'positivo':
            if len(problemas) <= 1 and indice_bem_estar >= 40:
                problemas = []  # Limpar problemas menores se o coment√°rio √© positivo
        
        return {
            'indice_bem_estar': round(indice_bem_estar, 1),
            'classificacao': classificacao,
            'cor': cor,
            'problemas': problemas,
            'recomendacao': self._gerar_recomendacao(classificacao, problemas)
        }
    
    def _gerar_recomendacao(self, classificacao, problemas):
        """Gera recomenda√ß√µes baseadas na an√°lise"""
        recomendacoes = {
            'cr√≠tico': 'Aten√ß√£o imediata necess√°ria! Considere conversar com RH ou psic√≥logo.',
            'preocupante': 'Situa√ß√£o merece aten√ß√£o. Busque apoio e considere pausas regulares.',
            'moderado': 'Estado emocional equilibrado, mas pode melhorar. Pratique autocuidado.',
            'bom': 'Voc√™ est√° indo bem! Continue cuidando da sua sa√∫de mental.',
            'excelente': 'Excelente! Voc√™ est√° em √≥timo estado emocional.'
        }
        
        recomendacao = recomendacoes.get(classificacao, '')
        
        if problemas:
            recomendacao += f" Pontos de aten√ß√£o: {', '.join(problemas)}."
        
        return recomendacao


# Inst√¢ncia global
analyzer = SentimentAnalyzer()

